{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aperture_Ray_Trace_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/kunguz/odak.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "7A_68nRQ-Pg0",
        "outputId": "cd99de0b-52c9-4cfd-d640-224766f9aadc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/kunguz/odak.git\n",
            "  Cloning https://github.com/kunguz/odak.git to /tmp/pip-req-build-nbtu7ah2\n",
            "  Running command git clone -q https://github.com/kunguz/odak.git /tmp/pip-req-build-nbtu7ah2\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (1.12.0+cu113)\n",
            "Collecting pillow>=8.1.2\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 28.4 MB/s \n",
            "\u001b[?25hCollecting plyfile>=0.7.2\n",
            "  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: tqdm>=4.61.1 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.12.0->odak==0.2.1) (4.1.1)\n",
            "Building wheels for collected packages: odak\n",
            "  Building wheel for odak (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for odak: filename=odak-0.2.1-py3-none-any.whl size=116476 sha256=55066b377d813a7b15f13167ff3f1255761262579a81798e156e7e07333b5b60\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6hyovw7y/wheels/5b/1f/1a/1d2de547c1d893422b054c9aea06da6ce4efbf401114444959\n",
            "Successfully built odak\n",
            "Installing collected packages: plyfile, pillow, odak\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed odak-0.2.1 pillow-9.2.0 plyfile-0.7.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import odak\n",
        "import torch \n",
        "import numpy as np \n",
        "import sys\n",
        "import odak.learn.raytracing as ODL\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import odak.raytracing as raytracer\n",
        "import odak.tools as tools\n",
        "import odak.raytracing as raytracer\n",
        "from odak.raytracing.ray import create_ray\n",
        "import cv2\n",
        "import sys"
      ],
      "metadata": {
        "id": "TOKZziua-QIH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "ik8-o4ao-TIT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tTNI7rGR7szQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Xxvvjms_-JAR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "class aperture_array():\n",
        "\n",
        "  def __init__(self, device):\n",
        "    self.device = device\n",
        "    self.init_light_sources()\n",
        "    self.init_aperture_array()\n",
        "    self.init_detector()\n",
        "  \n",
        "  def init_light_sources(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.):\n",
        "      x = torch.linspace(-dimensions[0]/2., dimensions[0]/2., pixel_count[0])\n",
        "      y = torch.linspace(-dimensions[1]/2., dimensions[1]/2., pixel_count[1])\n",
        "      X, Y = torch.meshgrid(x, y, indexing='ij')\n",
        "      self.light_source_locations = torch.zeros(X.shape[0], X.shape[1], 3).to(self.device)\n",
        "      self.light_source_locations[:, :, 0] = X\n",
        "      self.light_source_locations[:, :, 1] = Y\n",
        "      self.light_source_locations[:, :, 2] = Z\n",
        "      \n",
        "      \n",
        "  def init_aperture_array(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.01):\n",
        "        x = torch.linspace(-dimensions[0]/2., dimensions[0]/2., pixel_count[0])\n",
        "        y = torch.linspace(-dimensions[1]/2., dimensions[1]/2., pixel_count[1])\n",
        "        X, Y = torch.meshgrid(x, y, indexing='ij')\n",
        "        self.aperture_array_locations = torch.zeros(X.shape[0], X.shape[1], 3).to(self.device)\n",
        "        self.aperture_array_locations[:, :, 0] = X\n",
        "        self.aperture_array_locations[:, :, 1] = Y\n",
        "        self.aperture_array_locations[:, :, 2] = Z\n",
        "        self.aperture_array = torch.rand(X.shape[0], X.shape[1], requires_grad=True).to(self.device) # makes it differentiable\n",
        "        \n",
        "  def init_detector(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.05):\n",
        "        points = torch.tensor([0., 0, Z]).to(self.device)\n",
        "        self.detector_surface = odak.learn.raytracing.define_plane(points)\n",
        "        \n",
        "        # Locations of my pixels on my detector could be defined here.\n",
        "        \n",
        "  def intersection_points_to_image(self, points, amplitudes):\n",
        "        # Intersection points and paint an image on a detector?\n",
        "\n",
        "        self.focal_length= torch.tensor([5,5])\n",
        "        \n",
        "        W = torch.tensor([0., 0., 0.]).to(self.device)\n",
        "        location= self.aperture_array_locations.view(-1, 3)# make this the aperture array locations?\n",
        "\n",
        "        \n",
        "        # Creating the pinhole intrinsic matrix\n",
        "        camera_Intrinsic= torch.tensor([[self.focal_length[0], 0., 0.],\n",
        "                           [0.,self.focal_length[1], 0.], \n",
        "                           [0., 0., 1.]]).to(self.device)\n",
        "\n",
        "\n",
        "        # Creating extrinsic parameters(example)\n",
        "        Rotation= torch.tensor([[1., 0., 0.],\n",
        "                         [0., 1., 0.], \n",
        "                         [0., 0., 1.]]).to(self.device)\n",
        "        \n",
        "        one=torch.tensor([1]).to(self.device)\n",
        "        coordinates= []\n",
        "        for i in range(len(points)): \n",
        "\n",
        "          Translation = (W-location[i]).view(3, 1)\n",
        "          t=-torch.matmul(Rotation, Translation)\n",
        "\n",
        "          Rt=torch.cat((Rotation, t), 1)\n",
        "\n",
        "          P_matrix= torch.matmul(camera_Intrinsic, Rt)\n",
        "\n",
        "          # making the points a 4 x 1 matrix\n",
        "          new_point= torch.hstack((points[i], one)).view(4, 1)\n",
        "          cam_cood = torch.matmul(P_matrix, new_point).flatten()\n",
        "      \n",
        "          # camera coordinates\n",
        "          u=int(cam_cood[0]/ cam_cood[2])\n",
        "          v= int(cam_cood[1]/ cam_cood[2]) \n",
        "          result =[u, v]\n",
        "\n",
        "          coordinates.append(result)\n",
        "\n",
        "        new_coords= torch.tensor(coordinates).to(self.device)\n",
        "      \n",
        "        # this gives the coordinates on the 2D image plane\n",
        "        \n",
        "        detector= torch.zeros((20, 30, 3)).to(self.device)\n",
        "        \n",
        "        for k in range(len(new_coords)): \n",
        "         \n",
        "            #giving the indexed parts a value of 1 to make it visible\n",
        "            detector[new_coords[k][0].long(), new_coords[k][1].long()] = 1.\n",
        "\n",
        "        return detector\n",
        "  \n",
        "  def forward(self):\n",
        "        light_source_locations = self.light_source_locations.view(-1, 3)\n",
        "\n",
        "        aperture_array_locations = self.aperture_array_locations.view(-1, 3)\n",
        "\n",
        "        aperture_array = self.aperture_array.view(-1, 3)\n",
        "        #print(aperture_array.shape)\n",
        "        for light_source_location in light_source_locations:\n",
        "            rays_from_light_source = odak.learn.raytracing.create_ray_from_two_points(light_source_location, aperture_array_locations)\n",
        "            intersection_normals_w_detector, _ = odak.learn.raytracing.intersect_w_surface(rays_from_light_source, self.detector_surface)\n",
        "            intersection_points_w_detector = intersection_normals_w_detector[:, 0]\n",
        "            detector_image = self.intersection_points_to_image(\n",
        "                                                                intersection_points_w_detector,\n",
        "                                                                aperture_array\n",
        "                                                              )\n",
        "        return detector_image\n",
        "            \n",
        "  def optimize(self):\n",
        "        self.forward()\n",
        "        return None\n",
        "  \n",
        "def main():\n",
        "    device = torch.device('cuda')\n",
        "    apertures = aperture_array(device=device)\n",
        "    result = apertures.optimize()\n",
        "    return True\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     sys.exit(main())\n",
        "\n",
        "\n",
        "\n",
        "test= aperture_array('cuda')\n",
        "final_im= test.forward()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin = final_im.view(20, 30, 3)\n",
        "\n",
        "plt.imshow(fin.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3dJMm0A_6Ld3",
        "outputId": "2d8fe82d-fd3d-4034-9d0a-6560641c651e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f52a3f04290>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}