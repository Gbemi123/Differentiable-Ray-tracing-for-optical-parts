{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aperture_Ray_Trace_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/kunguz/odak.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A_68nRQ-Pg0",
        "outputId": "87b42894-cff4-4566-9aa6-6c9f4663f7c8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/kunguz/odak.git\n",
            "  Cloning https://github.com/kunguz/odak.git to /tmp/pip-req-build-eqrj83uq\n",
            "  Running command git clone -q https://github.com/kunguz/odak.git /tmp/pip-req-build-eqrj83uq\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (1.12.0+cu113)\n",
            "Requirement already satisfied: pillow>=8.1.2 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (9.2.0)\n",
            "Requirement already satisfied: plyfile>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (0.7.4)\n",
            "Requirement already satisfied: tqdm>=4.61.1 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.12.0->odak==0.2.1) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import odak\n",
        "import torch \n",
        "import numpy as np \n",
        "import sys\n",
        "import odak.learn.raytracing as ODL\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import odak.raytracing as raytracer\n",
        "import odak.tools as tools\n",
        "import odak.raytracing as raytracer\n",
        "from odak.raytracing.ray import create_ray\n",
        "import cv2\n",
        "import sys\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "TOKZziua-QIH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tTNI7rGR7szQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Xxvvjms_-JAR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "class aperture_array():\n",
        "\n",
        "  def __init__(self, device, image):\n",
        "    self.device = device\n",
        "    self.image =image.to(device).view(-1,1)\n",
        "    self.init_light_sources()\n",
        "    self.init_aperture_array()\n",
        "    self.init_detector()\n",
        "  \n",
        "  def init_light_sources(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.):\n",
        "      x = torch.linspace(-dimensions[0]/2., dimensions[0]/2., pixel_count[0])\n",
        "      y = torch.linspace(-dimensions[1]/2., dimensions[1]/2., pixel_count[1])\n",
        "      X, Y = torch.meshgrid(x, y, indexing='ij')\n",
        "      self.light_source_locations = torch.zeros(X.shape[0], X.shape[1], 3).to(self.device)\n",
        "      self.light_source_locations[:, :, 0] = X\n",
        "      self.light_source_locations[:, :, 1] = Y\n",
        "      self.light_source_locations[:, :, 2] = Z\n",
        "      \n",
        "      \n",
        "  def init_aperture_array(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.01):\n",
        "        x = torch.linspace(-dimensions[0]/2., dimensions[0]/2., pixel_count[0])\n",
        "        y = torch.linspace(-dimensions[1]/2., dimensions[1]/2., pixel_count[1])\n",
        "        X, Y = torch.meshgrid(x, y, indexing='ij')\n",
        "        self.aperture_array_locations = torch.zeros(X.shape[0], X.shape[1], 3).to(self.device)\n",
        "        self.aperture_array_locations[:, :, 0] = X\n",
        "        self.aperture_array_locations[:, :, 1] = Y\n",
        "        self.aperture_array_locations[:, :, 2] = Z\n",
        "        self.aperture_array = torch.rand(X.shape[0], X.shape[1], requires_grad=True).to(self.device) # makes it differentiable\n",
        "\n",
        "        \n",
        "        \n",
        "  def init_detector(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.01):\n",
        "        points = torch.tensor([0., 0, Z]).to(self.device)\n",
        "        self.detector_surface = odak.learn.raytracing.define_plane(points)\n",
        "        \n",
        "        # Locations of my pixels on my detector could be defined here.\n",
        "        \n",
        "  def intersection_points_to_image(self, points, amplitudes):\n",
        "   \n",
        "        Points_data= self.image/amplitudes\n",
        "        detector = torch.zeros_like(Points_data)\n",
        "\n",
        "        for idx, point in enumerate(points):\n",
        "          dist_btwn_array_npoint = torch.sqrt(torch.sum((self.aperture_array_locations-point)**2, dim=1))\n",
        "          min_dist_idx  = torch.argmin(dist_btwn_array_npoint)\n",
        "          \n",
        "          detector[min_dist_idx] = Points_data[idx]\n",
        "        detector= detector.view(20,30)\n",
        "        return detector\n",
        "  \n",
        "  def forward(self):\n",
        "        light_source_locations = self.light_source_locations.view(-1, 3)\n",
        "\n",
        "        aperture_array_locations = self.aperture_array_locations.view(-1, 3)\n",
        "      \n",
        "        aperture_array = self.aperture_array.view(-1, 1)\n",
        "        \n",
        "        \n",
        "        for light_source_location in light_source_locations:\n",
        "            rays_from_light_source = odak.learn.raytracing.create_ray_from_two_points(light_source_location, aperture_array_locations)\n",
        "\n",
        "            # print('rays from light: ', rays_from_light_source.size()) #600x2x3\n",
        "            intersection_normals_w_detector, _ = odak.learn.raytracing.intersect_w_surface(rays_from_light_source, self.detector_surface)\n",
        "            intersection_points_w_detector = intersection_normals_w_detector[:, 0]\n",
        "\n",
        "            # print(intersection_points_w_detector.size())\n",
        "            detector_image = self.intersection_points_to_image(\n",
        "                                                                intersection_points_w_detector,\n",
        "                                                                aperture_array\n",
        "                                                              )\n",
        "           \n",
        "        return detector_image\n",
        "\n",
        "  def compute_loss(self, output , target):\n",
        "\n",
        "    loss = torch.nn.MSELoss()(output, target )\n",
        "\n",
        "    return loss\n",
        "            \n",
        "  def optimize(self):\n",
        "\n",
        "        output= self.forward()\n",
        "        target= self.image\n",
        "\n",
        "\n",
        "        array = self.aperture_array\n",
        "       \n",
        "        optimiser= torch.optim.SGD(array,torch.tensor(0.1))\n",
        "        epochs= 50\n",
        "\n",
        "        # running_loss= 1\n",
        "        # for epoch in range(0, epochs+1):\n",
        "        #   print('\\rEpoch {}/{} - loss:{}'.format(epoch, epochs, running_loss))\n",
        "        #   optimiser.zero_grad()\n",
        "  \n",
        "          \n",
        "\n",
        "        #   loss = self.compute_loss(output,target )\n",
        "        #   running_loss+= loss\n",
        "        #   loss.backward()\n",
        "\n",
        "        #   optimiser.step()\n",
        "\n",
        "        return optimiser\n",
        "  \n",
        "def main():\n",
        "    device = torch.device('cuda')\n",
        "    apertures = aperture_array(device=device)\n",
        "    result = apertures.optimize()\n",
        "    return True\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     sys.exit(main())\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/Lenna.png')\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_gray= cv2.resize(img_gray, (20, 30))\n",
        "img_G= torch.tensor(img_gray)\n",
        "# plt.imshow(img_gray, cmap='gray')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "test= aperture_array(device, img_G)\n",
        "final_im= test.forward()\n"
      ],
      "metadata": {
        "id": "T_MFOL7j9sL5"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fin = final_im\n",
        "\n",
        "plt.imshow(fin.cpu().detach().numpy(), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3dJMm0A_6Ld3",
        "outputId": "da90ff31-3b54-4738-b24a-c9424da0ca9f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe1b1c91850>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim = test.optimize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "3OiZGjIoIo0l",
        "outputId": "81a8f064-e76d-4846-b6a3-23c98d488b5c"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-1ae4fcefaf11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-81-eff8b32892a3>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maperture_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moptimiser\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable)\u001b[0m\n\u001b[1;32m     88\u001b[0m                         \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                         maximize=maximize, foreach=foreach, capturable=capturable)\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     40\u001b[0m             raise TypeError(\"params argument given to the optimizer should be \"\n\u001b[1;32m     41\u001b[0m                             \u001b[0;34m\"an iterable of Tensors or dicts, but got \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                             torch.typename(params))\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TXkyleefmGHa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}