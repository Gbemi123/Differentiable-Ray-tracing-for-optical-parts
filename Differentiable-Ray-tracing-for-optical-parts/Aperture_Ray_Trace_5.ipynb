{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aperture_Ray_Trace_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/kunguz/odak.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "7A_68nRQ-Pg0",
        "outputId": "718f8dc9-f11f-4472-9958-5ec6bb9e178c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/kunguz/odak.git\n",
            "  Cloning https://github.com/kunguz/odak.git to /tmp/pip-req-build-ereevvfx\n",
            "  Running command git clone -q https://github.com/kunguz/odak.git /tmp/pip-req-build-ereevvfx\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (1.12.0+cu113)\n",
            "Collecting pillow>=8.1.2\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 8.7 MB/s \n",
            "\u001b[?25hCollecting plyfile>=0.7.2\n",
            "  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: tqdm>=4.61.1 in /usr/local/lib/python3.7/dist-packages (from odak==0.2.1) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.12.0->odak==0.2.1) (4.1.1)\n",
            "Building wheels for collected packages: odak\n",
            "  Building wheel for odak (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for odak: filename=odak-0.2.1-py3-none-any.whl size=116322 sha256=ac6e68289dfdf07ae615a07e4981c4f312e80aaaab22d86c6ce536c2dc2ac76d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-85v5x600/wheels/5b/1f/1a/1d2de547c1d893422b054c9aea06da6ce4efbf401114444959\n",
            "Successfully built odak\n",
            "Installing collected packages: plyfile, pillow, odak\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "Successfully installed odak-0.2.1 pillow-9.2.0 plyfile-0.7.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import odak\n",
        "import torch \n",
        "import numpy as np \n",
        "import sys\n",
        "import odak.learn.raytracing as ODL\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import odak.raytracing as raytracer\n",
        "import odak.tools as tools\n",
        "import odak.raytracing as raytracer\n",
        "from odak.raytracing.ray import create_ray\n",
        "import cv2\n",
        "import sys\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "TOKZziua-QIH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tTNI7rGR7szQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Xxvvjms_-JAR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "class aperture_array():\n",
        "\n",
        "  def __init__(self, device, image):\n",
        "    self.device = device\n",
        "    self.image =image.to(device).view(-1,1)\n",
        "    self.init_light_sources()\n",
        "    self.init_aperture_array()\n",
        "    self.init_detector()\n",
        "  \n",
        "  def init_light_sources(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.):\n",
        "      x = torch.linspace(-dimensions[0]/2., dimensions[0]/2., pixel_count[0])\n",
        "      y = torch.linspace(-dimensions[1]/2., dimensions[1]/2., pixel_count[1])\n",
        "      X, Y = torch.meshgrid(x, y, indexing='ij')\n",
        "      self.light_source_locations = torch.zeros(X.shape[0], X.shape[1], 3).to(self.device)\n",
        "      self.light_source_locations[:, :, 0] = X\n",
        "      self.light_source_locations[:, :, 1] = Y\n",
        "      self.light_source_locations[:, :, 2] = Z\n",
        "      \n",
        "      \n",
        "  def init_aperture_array(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.01):\n",
        "        x = torch.linspace(-dimensions[0]/2., dimensions[0]/2., pixel_count[0])\n",
        "        y = torch.linspace(-dimensions[1]/2., dimensions[1]/2., pixel_count[1])\n",
        "        X, Y = torch.meshgrid(x, y, indexing='ij')\n",
        "        self.aperture_array_locations = torch.zeros(X.shape[0], X.shape[1], 3).to(self.device)\n",
        "        self.aperture_array_locations[:, :, 0] = X\n",
        "        self.aperture_array_locations[:, :, 1] = Y\n",
        "        self.aperture_array_locations[:, :, 2] = Z\n",
        "        self.aperture_array = torch.rand(X.shape[0], X.shape[1], requires_grad=True, device=self.device)  #.to(self.device) # makes it differentiable\n",
        "\n",
        "        \n",
        "        \n",
        "  def init_detector(self, dimensions=[0.01, 0.015], pixel_count=[20, 30], Z=0.01):\n",
        "        points = torch.tensor([0., 0, Z]).to(self.device)\n",
        "        self.detector_surface = odak.learn.raytracing.define_plane(points)\n",
        "        \n",
        "        # Locations of my pixels on my detector could be defined here.\n",
        "        \n",
        "  def intersection_points_to_image(self, points, amplitudes):\n",
        "   \n",
        "        Points_data= self.image * amplitudes\n",
        "        detector = torch.zeros_like(Points_data)\n",
        "\n",
        "        for idx, point in enumerate(points):\n",
        "          dist_btwn_array_npoint = torch.sqrt(torch.sum((self.aperture_array_locations-point)**2, dim=1))\n",
        "          min_dist_idx  = torch.argmin(dist_btwn_array_npoint)\n",
        "          \n",
        "          detector[min_dist_idx] = Points_data[idx]\n",
        "        detector= detector.view(20,30)\n",
        "        return detector\n",
        "  \n",
        "  def forward(self):\n",
        "        light_source_locations = self.light_source_locations.view(-1, 3)\n",
        "\n",
        "        aperture_array_locations = self.aperture_array_locations.view(-1, 3)\n",
        "      \n",
        "        aperture_array = self.aperture_array.view(-1, 1)\n",
        "        \n",
        "        \n",
        "        for light_source_location in light_source_locations:\n",
        "            rays_from_light_source = odak.learn.raytracing.create_ray_from_two_points(light_source_location, aperture_array_locations)\n",
        "\n",
        "            # print('rays from light: ', rays_from_light_source.size()) #600x2x3\n",
        "            intersection_normals_w_detector, _ = odak.learn.raytracing.intersect_w_surface(rays_from_light_source, self.detector_surface)\n",
        "            intersection_points_w_detector = intersection_normals_w_detector[:, 0]\n",
        "\n",
        "            # print(intersection_points_w_detector.size())\n",
        "            detector_image = self.intersection_points_to_image(\n",
        "                                                                intersection_points_w_detector,\n",
        "                                                                aperture_array\n",
        "                                                              )\n",
        "           \n",
        "        return detector_image\n",
        "\n",
        "  def compute_loss(self, output , target):\n",
        "\n",
        "    loss = torch.nn.MSELoss()(output, target )\n",
        "\n",
        "    return loss\n",
        "            \n",
        "  def optimize(self):\n",
        "\n",
        "        output= self.forward().view(-1,1)\n",
        "        target= self.image\n",
        "\n",
        "\n",
        "        array = self.aperture_array\n",
        "       \n",
        "        optimiser= torch.optim.SGD([array],0.01)\n",
        "        epochs= 100\n",
        "\n",
        "        running_loss= 1\n",
        "        for epoch in range(0, epochs+1):\n",
        "          print('\\rEpoch {}/{} - loss:{}'.format(epoch, epochs, running_loss/len(array)), end=\"\")\n",
        "          optimiser.zero_grad()\n",
        "  \n",
        "          \n",
        "\n",
        "          loss = self.compute_loss(output.float(),target.float() )\n",
        "          running_loss+= loss\n",
        "          loss.backward(retain_graph=True)\n",
        "\n",
        "          optimiser.step()\n",
        "\n",
        "        return optimiser\n",
        "  \n",
        "def main():\n",
        "    device = torch.device('cuda')\n",
        "    apertures = aperture_array(device=device)\n",
        "    result = apertures.optimize()\n",
        "    return True\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     sys.exit(main())\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/IP Labs/Images/Lenna.png')\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_gray= cv2.resize(img_gray, (20, 30))\n",
        "img_G= torch.tensor(img_gray)\n",
        "# plt.imshow(img_gray, cmap='gray')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "test= aperture_array(device, img_G)\n",
        "final_im= test.forward()\n"
      ],
      "metadata": {
        "id": "T_MFOL7j9sL5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fin = final_im\n",
        "\n",
        "plt.imshow(fin.cpu().detach().numpy(), cmap='gray')"
      ],
      "metadata": {
        "id": "3dJMm0A_6Ld3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ffc30e36-5a24-4486-de9e-3fdb3a56099c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0b171b7d10>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim = test.optimize()"
      ],
      "metadata": {
        "id": "3OiZGjIoIo0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9638d7ad-ea68-47c4-fd21-8608b6f3b261"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/100 - loss:84225.4921875"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rand[0][0]"
      ],
      "metadata": {
        "id": "HQ3JtI2L2yxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tV57TnMU272H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}